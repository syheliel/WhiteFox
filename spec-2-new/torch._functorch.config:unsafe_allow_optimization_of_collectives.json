{
    "summary": "\nThe unsafe_allow_optimization_of_collectives flag controls whether collective operations (like all-reduce) can be optimized during compilation. When set to False (default), it prevents optimizations that could lead to deadlocks in distributed scenarios by:\n1. Preventing dead-code elimination of collectives\n2. Preventing recomputation of collectives during partitioning\n3. Ensuring consistent behavior across different ranks\n4. Maintaining the original execution order of collective operations\n```\n\n```python\nimport torch\nimport torch.distributed as dist\n\ndef collective_example():\n    dist.init_process_group('gloo')\n    tensor = torch.ones(1)\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n    return tensor\n```\n\n```yaml\n- torch.distributed.all_reduce\n- torch.distributed.broadcast\n- torch.distributed.reduce\n- torch.distributed.all_gather\n- torch.distributed.gather\n- torch.distributed.scatter\n",
    "python_code": "\nimport torch\nimport torch.distributed as dist\n\ndef collective_example():\n    dist.init_process_group('gloo')\n    tensor = torch.ones(1)\n    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n    return tensor\n```\n\n```yaml\n- torch.distributed.all_reduce\n- torch.distributed.broadcast\n- torch.distributed.reduce\n- torch.distributed.all_gather\n- torch.distributed.gather\n- torch.distributed.scatter\n",
    "api": [
        "torch.distributed.all_reduce",
        "torch.distributed.broadcast",
        "torch.distributed.reduce",
        "torch.distributed.all_gather",
        "torch.distributed.gather",
        "torch.distributed.scatter"
    ]
}