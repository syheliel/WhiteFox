{
    "summary": "\nThe canonicalize_quant_mapping function handles quantization mapping transformations in PyTorch graphs. The vulnerable line updates quantization options metadata for replacement nodes during graph transformation. This is important because:\n1. Quantization options control how tensors are quantized/dequantized\n2. Incomplete handling could lead to incorrect quantization behavior\n3. Metadata must be properly propagated through graph transformations\n4. Missing validation could result in mismatched quantization schemes\n```\n\n```python\nimport torch\nimport torch.nn as nn\n\nclass QuantizedModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(10, 10)\n        \n    def forward(self, x):\n        x = self.linear(x)\n        return torch.ops.higher_order.invoke_quant_packed(\n            lambda y: y, \n            'quant_invoke_0_0', \n            (x, x),\n            quant_options=torch._higher_order_ops.InvokeQuant()\n        )\n```\n\n```yaml\n- torch.ops.higher_order.invoke_quant_packed\n- torch._higher_order_ops.InvokeQuant\n- torch.ops.higher_order.invoke_quant\n",
    "python_code": "\nimport torch\nimport torch.nn as nn\n\nclass QuantizedModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(10, 10)\n        \n    def forward(self, x):\n        x = self.linear(x)\n        return torch.ops.higher_order.invoke_quant_packed(\n            lambda y: y, \n            'quant_invoke_0_0', \n            (x, x),\n            quant_options=torch._higher_order_ops.InvokeQuant()\n        )\n```\n\n```yaml\n- torch.ops.higher_order.invoke_quant_packed\n- torch._higher_order_ops.InvokeQuant\n- torch.ops.higher_order.invoke_quant\n",
    "api": [
        "torch.ops.higher_order.invoke_quant_packed",
        "torch._higher_order_ops.InvokeQuant",
        "torch.ops.higher_order.invoke_quant"
    ]
}